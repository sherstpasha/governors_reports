{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стандартные библиотеки\n",
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "from IPython.display import Image\n",
    "from ipywidgets import interact, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Импорты из внешних пакетов (Detectron2)\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import load_coco_json, register_coco_instances\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import detectron2\n",
    "import detectron2.data.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('detectron2')\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_train_path = 'data/train/annotations_train.json'\n",
    "annotations_validation_path = 'data/validation/annotations_validation.json'\n",
    "images_path = 'data/images'\n",
    "binary_mask_path = 'data/binary_mask_train.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def check_gpu_availability():\n",
    "    if torch.cuda.is_available():    \n",
    "        device = torch.device(\"cuda\")\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "\n",
    "def show_images(file_id, dataset, metadata):\n",
    "    example = dataset[file_id]\n",
    "    image = utils.read_image(example[\"file_name\"], format=\"RGB\")\n",
    "    plt.figure(figsize=(3,3),dpi=200)\n",
    "    visualizer = Visualizer(image[:, :, ::-1], metadata=metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(example)\n",
    "    plt.imshow(vis.get_image()[:, :,::-1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def f1_loss(y_actual, y_predicted):\n",
    "    true_positive = np.sum(y_actual & y_predicted)\n",
    "    false_positive = np.sum(~y_actual & y_predicted)\n",
    "    false_negative = np.sum(y_actual & ~y_predicted)\n",
    "    \n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    precision = true_positive / (true_positive + false_positive + epsilon)\n",
    "    recall = true_positive / (true_positive + false_negative + epsilon)\n",
    "    \n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "    return f1\n",
    "\n",
    "\n",
    "class custom_mapper:\n",
    "    def __init__(self, cfg):\n",
    "        self.transform_list = [\n",
    "            T.ResizeShortestEdge(\n",
    "                [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST],\n",
    "                cfg.INPUT.MAX_SIZE_TEST),\n",
    "            T.RandomBrightness(0.9, 1.1),\n",
    "            T.RandomContrast(0.9, 1.1),\n",
    "            T.RandomSaturation(0.9, 1.1),\n",
    "            T.RandomLighting(0.9)\n",
    "        ]\n",
    "        print(f\"[custom_mapper]: {self.transform_list}\")\n",
    "\n",
    "    def __call__(self, dataset_dict):\n",
    "        dataset_dict = copy.deepcopy(dataset_dict)\n",
    "        image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    \n",
    "        image, transforms = T.apply_transform_gens(self.transform_list, image)\n",
    "        dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "        annos = [\n",
    "            utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "            for obj in dataset_dict.pop(\"annotations\")\n",
    "            if obj.get(\"iscrowd\", 0) == 0\n",
    "        ]\n",
    "\n",
    "        instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "        dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "        return dataset_dict\n",
    "\n",
    "\n",
    "CHECKPOINTS_RESULTS = []\n",
    "\n",
    "class F1Evaluator(DatasetEvaluator):\n",
    "    def __init__(self):\n",
    "        self.loaded_true = np.load(binary_mask_path)\n",
    "        self.val_predictions = {}\n",
    "        self.f1_scores = []\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val_predictions = {}\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            filename = input[\"file_name\"].split(\"/\")[-1]\n",
    "            if filename != \"41_3.JPG\":\n",
    "                true = self.loaded_true[filename].reshape(-1)\n",
    "\n",
    "                prediction = output['instances'].pred_masks.cpu().numpy()\n",
    "                mask = np.add.reduce(prediction)\n",
    "                mask = (mask > 0).reshape(-1)\n",
    "\n",
    "                self.f1_scores.append(f1_loss(true, mask))\n",
    "\n",
    "    def evaluate(self):\n",
    "        global CHECKPOINTS_RESULTS\n",
    "        result = np.mean(self.f1_scores)\n",
    "        CHECKPOINTS_RESULTS.append(result)\n",
    "        return {\"meanF1\": result}\n",
    "    \n",
    "\n",
    "class AugTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper(cfg))\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return F1Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register(\"my_dataset_train\",lambda: load_coco_json(annotations_train_path,\n",
    "                                                                  image_root = images_path,\n",
    "                                                                  dataset_name=\"my_dataset_train\",\n",
    "                                                                  extra_annotation_keys=['bbox_mode']))\n",
    "DatasetCatalog.register(\"my_dataset_validation\",lambda: load_coco_json(annotations_validation_path,\n",
    "                                                                  image_root = images_path,\n",
    "                                                                  dataset_name=\"my_dataset_validation\",\n",
    "                                                                  extra_annotation_keys=['bbox_mode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DatasetCatalog.get(\"my_dataset_train\")\n",
    "dataset_validation = DatasetCatalog.get(\"my_dataset_validation\")\n",
    "print(f'Training dataset size (Images): {len(dataset_train)}')\n",
    "\n",
    "metadata_train = MetadataCatalog.get(\"my_dataset_train\")\n",
    "metadata_validation = MetadataCatalog.get(\"my_dataset_validation\")\n",
    "print(f'Validation dataset size (Images): {len(dataset_validation)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(file_id=0, dataset=dataset_train, metadata=metadata_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")) \n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''with open(annotations_train_path) as annotations_train:\n",
    "    annotations = json.load(annotations_train)\n",
    "    height, width = 10000, 10000\n",
    "    for element in annotations[\"images\"]:\n",
    "        height = min(height, element[\"height\"])\n",
    "        width = min(width, element[\"width\"])\n",
    "    print(height, width)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation datasets\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "\n",
    "# Parallel data loading\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "\n",
    "# Image compression\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = 2160\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 3130\n",
    "cfg.INPUT.MIN_SIZE_TEST = cfg.INPUT.MIN_SIZE_TRAIN\n",
    "cfg.INPUT.MAX_SIZE_TEST = cfg.INPUT.MAX_SIZE_TRAIN\n",
    "\n",
    "# Decision threshold\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1\n",
    "\n",
    "# Validation frequency\n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "\n",
    "# Checkpoint frequency\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = cfg.TEST.EVAL_PERIOD\n",
    "\n",
    "# Blue Green Red (BGR) channel format\n",
    "cfg.INPUT.FORMAT = 'BGR' \n",
    "\n",
    "# Batch size\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "\n",
    "# Learning rate\n",
    "cfg.SOLVER.BASE_LR = 0.01\n",
    "\n",
    "# Learning rate reduction frequency\n",
    "cfg.SOLVER.STEPS = (1500,)\n",
    "\n",
    "# Learning rate reduction factor\n",
    "cfg.SOLVER.GAMMA = 0.1\n",
    "\n",
    "# Number of training iterations\n",
    "cfg.SOLVER.MAX_ITER = 17000\n",
    "\n",
    "# Number of classes in the dataset\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "\n",
    "# Maximum number of words per page\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "\n",
    "# Model output path\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Remove previous outputs\n",
    "#%rm output/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = AugTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer\n",
    "clear_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(enumerate(CHECKPOINTS_RESULTS, start=1))\n",
    "# файл с результатами валидации на каждом прогоне\n",
    "with open(\"CHECKPOINTS_RESULTS.txt\", \"w\") as f:\n",
    "    f.write(str(results))\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
